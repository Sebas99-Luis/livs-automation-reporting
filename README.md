# üì¶ LIVS Automation Pipeline

Automatizaci√≥n diaria para ingesti√≥n, validaci√≥n, limpieza y carga de datos en PostgreSQL usando Docker y cron.

---

## üß≠ Descripci√≥n general

Este proyecto implementa un pipeline totalmente automatizado que procesa archivos CSV diarios provenientes del sistema de ventas de LIVS. El flujo incluye:

- Ingesta autom√°tica de archivos  
- Validaci√≥n y limpieza  
- Manejo de errores  
- Carga en PostgreSQL  
- Logging persistente  
- Ejecuci√≥n diaria mediante cron dentro de Docker  

El objetivo es entregar un sistema estable, reproducible y f√°cil de mantener, sin depender de instalaciones locales de Python.

---


## üîÑ Flujo del pipeline

<img width="1024" height="1024" alt="image" src="https://github.com/user-attachments/assets/232bd253-1ea6-4747-9520-f31aa5deab91" />



---

## ‚öôÔ∏è Funcionamiento del pipeline

### 1. Ingesta  
Los archivos CSV se colocan en `data/incoming/`.

### 2. Validaci√≥n  
Se revisan columnas obligatorias, tipos de datos y estructura.

### 3. Limpieza  
Correcciones de formato, normalizaci√≥n, manejo de nulos, estandarizaci√≥n de categor√≠as.

### 4. Manejo de errores  
Si un archivo falla validaci√≥n o limpieza:

- Se mueve a `data/bad/`  
- Se registra el error en `logs/pipeline.log`

### 5. Carga en PostgreSQL  
Los datos limpios se insertan en la tabla


### 6. Logging  
Cada ejecuci√≥n escribe:

- Fecha y hora  
- Archivo procesado  
- Registros insertados  
- Errores encontrados  

---


### 6. Logging  
Cada ejecuci√≥n escribe:

- Fecha y hora  
- Archivo procesado  
- Registros insertados  
- Errores encontrados  

---

## üê≥ Ejecuci√≥n con Docker

### Construir im√°genes
docker-compose build --no-cache

### Levantar servicios
docker-compose up -d

Esto inicia:

- `livs_db` ‚Üí PostgreSQL  
- `livs_pipeline` ‚Üí pipeline + cron  

---

## ‚è∞ Automatizaci√≥n con cron

El contenedor ejecuta el pipeline todos los d√≠as a las **06:00**.

Contenido del archivo `pipeline-cron`:
docker exec -it livs_pipeline sh -c "python /app/run_pipeline.py"


Revisar log:
tail -n 50 logs/pipeline.log


---

## üóÑÔ∏è Acceso a PostgreSQL

Conexi√≥n local:

- Host: `localhost`  
- Puerto: `5432`  
- Usuario: definido en `.env`  
- Base de datos: `livs`  

Ejemplo:
psql -h localhost -U postgres -d livs


---

## üìå Estado final del proyecto

Este proyecto entrega:

- Pipeline automatizado y reproducible  
- Procesamiento diario sin intervenci√≥n humana  
- Logs persistentes  
- Manejo robusto de errores  
- Datos limpios en PostgreSQL listos para an√°lisis  

El dashboard no forma parte de esta versi√≥n del proyecto.

---





